{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10361187,"sourceType":"datasetVersion","datasetId":6416956}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMAGE CLASSIFIER\n\nWe are going to build an image classifier that when given a picture, can classify whether it is an image or a fish","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T17:15:34.251555Z","iopub.execute_input":"2025-01-04T17:15:34.251978Z","iopub.status.idle":"2025-01-04T17:15:34.256700Z","shell.execute_reply.started":"2025-01-04T17:15:34.251944Z","shell.execute_reply":"2025-01-04T17:15:34.255474Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Dataset\n\nWe are going to use [imagenet](https://www.image-net.org/) a database with over hundred of thousands of images. It contains more than 14 million images and 20,000 image categories. Itâ€™s the standard that all image classifiers judge themselves against","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\n\n# Define a helper function to validate images\ndef is_valid_image(filepath):\n    try:\n        with Image.open(filepath) as img:\n            img.verify()  # Verify if it's a valid image\n        return True\n    except Exception:\n        return False\n\n# Custom ImageFolder to handle corrupted files\nclass SafeImageFolder(torchvision.datasets.ImageFolder):\n    def __init__(self, root, transform=None):\n        super().__init__(root, transform)\n        self.samples = [(path, label) for path, label in self.samples if is_valid_image(path)]\n\n# Data transforms\ndata_transforms = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# Train Data\ntrain_data_path = \"/kaggle/input/fish-or-cat/images/train\"\ntrain_data = SafeImageFolder(root=train_data_path, transform=data_transforms)\n\n# Validation Data\nval_data_path = \"/kaggle/input/fish-or-cat/images/val\"\nval_data = SafeImageFolder(root=val_data_path, transform=data_transforms)\n\n# Test Data\ntest_data_path = \"/kaggle/input/fish-or-cat/images/test\"\ntest_data = SafeImageFolder(root=test_data_path, transform=data_transforms)\n\n# Dataloaders\nbatch_size = 64\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T17:14:00.202232Z","iopub.execute_input":"2025-01-04T17:14:00.202641Z","iopub.status.idle":"2025-01-04T17:14:09.065256Z","shell.execute_reply.started":"2025-01-04T17:14:00.202611Z","shell.execute_reply":"2025-01-04T17:14:09.063832Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"config = {\n    \"batch\" : 64,\n    \"epochs\": 50\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T17:14:13.306353Z","iopub.execute_input":"2025-01-04T17:14:13.306783Z","iopub.status.idle":"2025-01-04T17:14:13.311271Z","shell.execute_reply.started":"2025-01-04T17:14:13.306745Z","shell.execute_reply":"2025-01-04T17:14:13.310155Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## DataLoader","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(train_data, batch_size = config[\"batch\"])\nval_dataloader = DataLoader(val_data, batch_size = config[\"batch\"])\ntest_dataloader = DataLoader(test_data, batch_size = config[\"batch\"])\n\nfor image, label in train_dataloader:\n    print(f\"{image.shape}, {label.shape}\")\n    # the image shape should be (batch_size, channels, height, width) - so the first layer of the network should be channel X height X width\n    # the label should be (64)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T17:20:03.494460Z","iopub.execute_input":"2025-01-04T17:20:03.494865Z","iopub.status.idle":"2025-01-04T17:20:03.851487Z","shell.execute_reply.started":"2025-01-04T17:20:03.494830Z","shell.execute_reply":"2025-01-04T17:20:03.850292Z"}},"outputs":[{"name":"stdout","text":"torch.Size([64, 3, 64, 64]), torch.Size([64])\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Model Architecture","metadata":{}},{"cell_type":"code","source":"class CatorFish(nn.Module):\n    def __init__(self):\n        super(CatorFish, self).__init__()\n        self.fc1 = nn.Linear(12288, 84)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(84, 50)\n        self.relu2 = nn.ReLU()\n        self.fc3 = nn.Linear(50, 2)\n        # self.softmax = nn.Softmax()\n\n    def forward(x, self):\n        x = x.view(-1, 12288) # flattening the image\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.relu2(x)\n        x = self.fc3(x)\n        # x = self.softmax(x)\n        return x\n        \nmodel = CatorFish()\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T17:29:53.791223Z","iopub.execute_input":"2025-01-04T17:29:53.791588Z","iopub.status.idle":"2025-01-04T17:29:53.817919Z","shell.execute_reply.started":"2025-01-04T17:29:53.791561Z","shell.execute_reply":"2025-01-04T17:29:53.816623Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"CatorFish(\n  (fc1): Linear(in_features=12288, out_features=84, bias=True)\n  (relu): ReLU()\n  (fc2): Linear(in_features=84, out_features=50, bias=True)\n  (relu2): ReLU()\n  (fc3): Linear(in_features=50, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}